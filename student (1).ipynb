{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "Clustering manufacturer names...\n",
      "Clustering product names...\n",
      "Saving mappings to file...\n",
      "Creating standardized dataset...\n",
      "\n",
      "Original unique manufacturer names: 4414\n",
      "Standardized unique manufacturer names: 3648\n",
      "Original unique product names: 13426\n",
      "Standardized unique product names: 8817\n",
      "Loading standardized dataset...\n",
      "Encoding text features with TF-IDF...\n",
      "Scaling numerical features...\n",
      "Combining features for clustering...\n",
      "Applying DBSCAN...\n",
      "Saving clustered results...\n",
      "Clusters found: 8 (excluding noise)\n",
      "Results saved to clustered_products.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from rapidfuzz import fuzz, process\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and standardize text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'[^\\w\\s-]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def fuzzy_standardize(names, threshold=85):\n",
    "    \"\"\"Use fuzzy matching to group similar names efficiently.\"\"\"\n",
    "    standardized = {}\n",
    "    processed = set()\n",
    "\n",
    "    for name in names:\n",
    "        if name in processed:\n",
    "            continue\n",
    "        \n",
    "        best_match = process.extractOne(name, standardized.keys(), scorer=fuzz.token_sort_ratio, score_cutoff=threshold)\n",
    "        \n",
    "        if best_match:\n",
    "            standardized[name] = standardized[best_match[0]]\n",
    "        else:\n",
    "            standardized[name] = name  # Assign itself if no good match\n",
    "        \n",
    "        processed.add(name)\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "def create_key(name):\n",
    "    \"\"\"Create standardized key for grouping similar names.\"\"\"\n",
    "    name = preprocess_text(name)\n",
    "    name = re.sub(r'\\b(ltd|limited|co|company|ea|east\\s+africa)\\b', '', name)\n",
    "    name = re.sub(r'[^a-z0-9]', '', name)\n",
    "    return name\n",
    "\n",
    "# Define known incorrect mappings\n",
    "INCORRECT_MAPPINGS = {\n",
    "    \"Mapato Feeds\": [\"Mazao Feeds\"],\n",
    "    \"murimi feeds\": [\"Mumbi feeds\"],\n",
    "}\n",
    "\n",
    "def should_exclude_mapping(name1, name2):\n",
    "    \"\"\"Check if two names should not be mapped together.\"\"\"\n",
    "    for standard_name, incorrect_vars in INCORRECT_MAPPINGS.items():\n",
    "        lower_standard = standard_name.lower()\n",
    "        lower_incorrects = [x.lower() for x in incorrect_vars]\n",
    "        if (name1.lower() == lower_standard and name2.lower() in lower_incorrects) or \\\n",
    "           (name2.lower() == lower_standard and name1.lower() in lower_incorrects):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Clustering functions\n",
    "def find_similar_names(name, names, threshold=85):\n",
    "    \"\"\"Find similar names using RapidFuzz.\"\"\"\n",
    "    return [other_name for other_name in names if fuzz.token_sort_ratio(name, other_name) >= threshold]\n",
    "\n",
    "def cluster_names(names, similarity_threshold=85):\n",
    "    \"\"\"Cluster similar names using fuzzy matching.\"\"\"\n",
    "    clusters = defaultdict(list)\n",
    "    remaining_names = set(names)\n",
    "    \n",
    "    while remaining_names:\n",
    "        current_name = remaining_names.pop()\n",
    "        current_cluster = [current_name]\n",
    "        \n",
    "        similar_names = find_similar_names(current_name, list(remaining_names), threshold=similarity_threshold)\n",
    "        similar_names = [name for name in similar_names if not should_exclude_mapping(current_name, name)]\n",
    "        \n",
    "        for similar_name in similar_names:\n",
    "            if similar_name in remaining_names:\n",
    "                current_cluster.append(similar_name)\n",
    "                remaining_names.remove(similar_name)\n",
    "        \n",
    "        standardized_name = current_cluster[0]\n",
    "        clusters[standardized_name].extend(current_cluster)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def create_mapping_dict(clusters):\n",
    "    \"\"\"Create mapping dictionary from variations to standardized names.\"\"\"\n",
    "    return {var: std for std, vars in clusters.items() for var in vars}\n",
    "\n",
    "# Data Cleaning & Standardization\n",
    "def clean_and_standardize_data(input_file='products_2.csv', similarity_threshold=85):\n",
    "    \"\"\"Main function to clean and standardize the dataset.\"\"\"\n",
    "    print(\"Reading dataset...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Drop rows with missing critical values\n",
    "    df.dropna(subset=['product_manufacturer_name', 'product_name'], inplace=True)\n",
    "    \n",
    "    # Cluster manufacturer names\n",
    "    print(\"Clustering manufacturer names...\")\n",
    "    manufacturer_names = df['product_manufacturer_name'].unique()\n",
    "    manufacturer_clusters = cluster_names(manufacturer_names, similarity_threshold)\n",
    "    manufacturer_mapping = create_mapping_dict(manufacturer_clusters)\n",
    "    \n",
    "    # Cluster product names\n",
    "    print(\"Clustering product names...\")\n",
    "    product_names = df['product_name'].unique()\n",
    "    product_clusters = cluster_names(product_names, similarity_threshold)\n",
    "    product_mapping = create_mapping_dict(product_clusters)\n",
    "    \n",
    "    # Save mapping details\n",
    "    print(\"Saving mappings to file...\")\n",
    "    with open('name_mappings_fuzzy.txt', 'w') as f:\n",
    "        f.write(\"=== Manufacturer Name Mappings ===\\n\\n\")\n",
    "        for standard_name, variations in manufacturer_clusters.items():\n",
    "            f.write(f\"Standard Name: {standard_name}\\n\")\n",
    "            f.write(\"Variations:\\n\")\n",
    "            for var in sorted(variations):\n",
    "                if var != standard_name:\n",
    "                    f.write(f\"  - {var}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"\\n=== Product Name Mappings ===\\n\\n\")\n",
    "        for standard_name, variations in product_clusters.items():\n",
    "            f.write(f\"Standard Name: {standard_name}\\n\")\n",
    "            f.write(\"Variations:\\n\")\n",
    "            for var in sorted(variations):\n",
    "                if var != standard_name:\n",
    "                    f.write(f\"  - {var}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    # Create standardized dataset\n",
    "    print(\"Creating standardized dataset...\")\n",
    "    df['product_manufacturer_name_std'] = df['product_manufacturer_name'].map(manufacturer_mapping)\n",
    "    df['product_name_std'] = df['product_name'].map(product_mapping)\n",
    "    \n",
    "    # Save standardized dataset\n",
    "    output_file = 'products_standardized_fuzzy.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nOriginal unique manufacturer names: {len(manufacturer_names)}\")\n",
    "    print(f\"Standardized unique manufacturer names: {len(df['product_manufacturer_name_std'].unique())}\")\n",
    "    print(f\"Original unique product names: {len(product_names)}\")\n",
    "    print(f\"Standardized unique product names: {len(df['product_name_std'].unique())}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clustering with DBSCAN\n",
    "def cluster_data(file_path='products_standardized_fuzzy.csv'):\n",
    "    print(\"Loading standardized dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.dropna(subset=['product_name_std', 'product_manufacturer_name_std', 'product_category_name', 'product_type_numeric'], inplace=True)\n",
    "    \n",
    "    print(\"Encoding text features with TF-IDF...\")\n",
    "    vectorizer_product = TfidfVectorizer()\n",
    "    vectorizer_manufacturer = TfidfVectorizer()\n",
    "    vectorizer_category = TfidfVectorizer()\n",
    "\n",
    "    product_tfidf = vectorizer_product.fit_transform(df['product_name_std'])\n",
    "    manufacturer_tfidf = vectorizer_manufacturer.fit_transform(df['product_manufacturer_name_std'])\n",
    "    category_tfidf = vectorizer_category.fit_transform(df['product_category_name'])\n",
    "    \n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "    type_numeric_scaled = scaler.fit_transform(df[['product_type_numeric']])\n",
    "    \n",
    "    print(\"Combining features for clustering...\")\n",
    "    feature_matrix = np.hstack((product_tfidf.toarray(), manufacturer_tfidf.toarray(), category_tfidf.toarray(), type_numeric_scaled))\n",
    "    \n",
    "    print(\"Applying DBSCAN...\")\n",
    "    clustering = DBSCAN(eps=0.5, min_samples=5, metric='cosine').fit(feature_matrix)\n",
    "    df['cluster'] = clustering.labels_\n",
    "    \n",
    "    print(\"Saving clustered results...\")\n",
    "    df.to_csv('clustered_products.csv', index=False)\n",
    "    \n",
    "    print(f\"Clusters found: {len(set(df['cluster'])) - 1} (excluding noise)\")\n",
    "    print(\"Results saved to clustered_products.csv\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the full pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    df_standardized = clean_and_standardize_data()\n",
    "    df_clustered = cluster_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_type_numeric</th>\n",
       "      <th>product_type_text</th>\n",
       "      <th>product_manufacturer_id</th>\n",
       "      <th>product_manufacturer_name</th>\n",
       "      <th>product_manufacturer_name_std</th>\n",
       "      <th>product_name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512842</td>\n",
       "      <td>Layers Mash</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Lucky Feeds</td>\n",
       "      <td>Lucky Feeds</td>\n",
       "      <td>Layer mash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513291</td>\n",
       "      <td>Layers Mash</td>\n",
       "      <td>313</td>\n",
       "      <td>Minerals and Supplements</td>\n",
       "      <td>70.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>Mapato Feeds</td>\n",
       "      <td>Mapato Feeds</td>\n",
       "      <td>Layer mash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514788</td>\n",
       "      <td>Layers Mash</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>10.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>5311.0</td>\n",
       "      <td>murimi feeds</td>\n",
       "      <td>murimi feeds</td>\n",
       "      <td>Layer mash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514789</td>\n",
       "      <td>Layers Mash</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>5311.0</td>\n",
       "      <td>murimi feeds</td>\n",
       "      <td>murimi feeds</td>\n",
       "      <td>Layer mash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>514845</td>\n",
       "      <td>Layers Mash</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>5.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>25878.0</td>\n",
       "      <td>Meru Central Ltd</td>\n",
       "      <td>Meru Central Ltd</td>\n",
       "      <td>Layer mash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49570</th>\n",
       "      <td>470588</td>\n",
       "      <td>bravo adult</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>15.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>23869.0</td>\n",
       "      <td>parikh packaging</td>\n",
       "      <td>parikh packaging</td>\n",
       "      <td>bravo adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49571</th>\n",
       "      <td>483762</td>\n",
       "      <td>bravo adult</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>15.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>7285.0</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49572</th>\n",
       "      <td>483820</td>\n",
       "      <td>bravo adult</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>2.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>7285.0</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49573</th>\n",
       "      <td>484386</td>\n",
       "      <td>bravo adult</td>\n",
       "      <td>318</td>\n",
       "      <td>Feeds</td>\n",
       "      <td>8.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>7285.0</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49574</th>\n",
       "      <td>525487</td>\n",
       "      <td>bravo adult</td>\n",
       "      <td>313</td>\n",
       "      <td>Minerals and Supplements</td>\n",
       "      <td>15.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>7285.0</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bravo adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49575 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id product_name  product_category_id     product_category_name  \\\n",
       "0      512842  Layers Mash                  318                     Feeds   \n",
       "1      513291  Layers Mash                  313  Minerals and Supplements   \n",
       "2      514788  Layers Mash                  318                     Feeds   \n",
       "3      514789  Layers Mash                  318                     Feeds   \n",
       "4      514845  Layers Mash                  318                     Feeds   \n",
       "...       ...          ...                  ...                       ...   \n",
       "49570  470588  bravo adult                  318                     Feeds   \n",
       "49571  483762  bravo adult                  318                     Feeds   \n",
       "49572  483820  bravo adult                  318                     Feeds   \n",
       "49573  484386  bravo adult                  318                     Feeds   \n",
       "49574  525487  bravo adult                  313  Minerals and Supplements   \n",
       "\n",
       "       product_type_numeric product_type_text  product_manufacturer_id  \\\n",
       "0                       1.0                kg                    608.0   \n",
       "1                      70.0                kg                   2314.0   \n",
       "2                      10.0                kg                   5311.0   \n",
       "3                       1.0                kg                   5311.0   \n",
       "4                       5.0                kg                  25878.0   \n",
       "...                     ...               ...                      ...   \n",
       "49570                  15.0                kg                  23869.0   \n",
       "49571                  15.0                kg                   7285.0   \n",
       "49572                   2.0                kg                   7285.0   \n",
       "49573                   8.0                kg                   7285.0   \n",
       "49574                  15.0                kg                   7285.0   \n",
       "\n",
       "      product_manufacturer_name product_manufacturer_name_std product_name_std  \n",
       "0                   Lucky Feeds                   Lucky Feeds       Layer mash  \n",
       "1                  Mapato Feeds                  Mapato Feeds       Layer mash  \n",
       "2                  murimi feeds                  murimi feeds       Layer mash  \n",
       "3                  murimi feeds                  murimi feeds       Layer mash  \n",
       "4              Meru Central Ltd              Meru Central Ltd       Layer mash  \n",
       "...                         ...                           ...              ...  \n",
       "49570          parikh packaging              parikh packaging      bravo adult  \n",
       "49571                     bravo                         bravo      bravo adult  \n",
       "49572                     bravo                         bravo      bravo adult  \n",
       "49573                     bravo                         bravo      bravo adult  \n",
       "49574                     bravo                         bravo      bravo adult  \n",
       "\n",
       "[49575 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('products_standardized_fuzzy.csv')\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
